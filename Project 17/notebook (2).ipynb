{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Project: Predicting Customer Churn for Interconnect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting AUC-ROC: 0.845\n",
      "Gradient Boosting Accuracy: 0.752\n",
      "\n",
      "üìä Updated Model Performance Comparison:\n",
      "\n",
      "              Model  AUC-ROC  Accuracy\n",
      "Logistic Regression 0.829962  0.792051\n",
      "      Random Forest 0.819498  0.789212\n",
      "  Gradient Boosting 0.845104  0.752307\n",
      "\n",
      "‚úÖ Best model based on AUC-ROC: Gradient Boosting\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 1: Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "\n",
    "# Step 2: Load Data\n",
    "contract = pd.read_csv('/datasets/final_provider/contract.csv')\n",
    "personal = pd.read_csv('/datasets/final_provider/personal.csv')\n",
    "internet = pd.read_csv('/datasets/final_provider/internet.csv')\n",
    "phone = pd.read_csv('/datasets/final_provider/phone.csv')\n",
    "\n",
    "# Step 3: Merge Data\n",
    "df = contract.merge(personal, on='customerID', how='left')\n",
    "df = df.merge(internet, on='customerID', how='left')\n",
    "df = df.merge(phone, on='customerID', how='left')\n",
    "\n",
    "# Step 4: Target Creation and Cleaning\n",
    "df['churn'] = df['EndDate'].apply(lambda x: 0 if x == 'No' else 1)\n",
    "internet_cols = ['InternetService', 'OnlineSecurity', 'OnlineBackup', 'DeviceProtection',\n",
    "                 'TechSupport', 'StreamingTV', 'StreamingMovies']\n",
    "df[internet_cols] = df[internet_cols].fillna('No internet service')\n",
    "df['MultipleLines'] = df['MultipleLines'].fillna('No phone service')\n",
    "\n",
    "# Step 5: Preprocessing\n",
    "df_model = df.copy()\n",
    "df_model = df_model.drop(['customerID', 'BeginDate', 'EndDate'], axis=1)\n",
    "\n",
    "binary_cols = ['gender', 'Partner', 'Dependents', 'PaperlessBilling', 'OnlineSecurity',\n",
    "               'OnlineBackup', 'DeviceProtection', 'TechSupport', 'StreamingTV',\n",
    "               'StreamingMovies', 'MultipleLines']\n",
    "multi_cols = ['Type', 'PaymentMethod', 'InternetService']\n",
    "\n",
    "for col in binary_cols:\n",
    "    df_model[col] = df_model[col].map({'Yes': 1, 'No': 0, 'Male': 1, 'Female': 0,\n",
    "                                       'No internet service': 0, 'No phone service': 0})\n",
    "\n",
    "df_model = pd.get_dummies(df_model, columns=multi_cols)\n",
    "\n",
    "# Convert TotalCharges to numeric\n",
    "df_model['TotalCharges'] = pd.to_numeric(df_model['TotalCharges'], errors='coerce')\n",
    "df_model['TotalCharges'] = df_model['TotalCharges'].fillna(0)\n",
    "\n",
    "# Step 6: Train-Test Split\n",
    "X = df_model.drop('churn', axis=1)\n",
    "y = df_model['churn']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "X_train = X_train.copy()\n",
    "X_test = X_test.copy()\n",
    "\n",
    "# Step 7: Scaling\n",
    "numeric_cols = ['MonthlyCharges', 'TotalCharges', 'SeniorCitizen']\n",
    "scaler = StandardScaler()\n",
    "X_train.loc[:, numeric_cols] = scaler.fit_transform(X_train[numeric_cols])\n",
    "X_test.loc[:, numeric_cols] = scaler.transform(X_test[numeric_cols])\n",
    "\n",
    "# Combine X_train and y_train for upsampling\n",
    "train_data = pd.concat([X_train, y_train], axis=1)\n",
    "\n",
    "# Split into classes\n",
    "majority = train_data[train_data['churn'] == 0]\n",
    "minority = train_data[train_data['churn'] == 1]\n",
    "\n",
    "# Upsample the minority class\n",
    "minority_upsampled = minority.sample(n=len(majority), replace=True, random_state=42)\n",
    "\n",
    "# Combine back into a balanced training set\n",
    "train_upsampled = pd.concat([majority, minority_upsampled])\n",
    "\n",
    "# Shuffle and split back\n",
    "X_train_balanced = train_upsampled.drop('churn', axis=1)\n",
    "y_train_balanced = train_upsampled['churn']\n",
    "\n",
    "# Train Gradient Boosting on upsampled data\n",
    "gb = GradientBoostingClassifier(random_state=42)\n",
    "gb.fit(X_train_balanced, y_train_balanced)\n",
    "\n",
    "# Predict\n",
    "gb_pred_prob = gb.predict_proba(X_test)[:, 1]\n",
    "gb_pred = gb.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "gb_auc = roc_auc_score(y_test, gb_pred_prob)\n",
    "gb_acc = accuracy_score(y_test, gb_pred)\n",
    "\n",
    "print(f\"Gradient Boosting AUC-ROC: {gb_auc:.3f}\")\n",
    "print(f\"Gradient Boosting Accuracy: {gb_acc:.3f}\")\n",
    "\n",
    "# Step 8: Logistic Regression\n",
    "logreg = LogisticRegression(max_iter=1000, random_state=42)\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred_prob = logreg.predict_proba(X_test)[:, 1]\n",
    "y_pred = logreg.predict(X_test)\n",
    "logreg_auc = roc_auc_score(y_test, y_pred_prob)\n",
    "logreg_acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Step 9: Random Forest\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "rf_pred_prob = rf.predict_proba(X_test)[:, 1]\n",
    "rf_pred = rf.predict(X_test)\n",
    "rf_auc = roc_auc_score(y_test, rf_pred_prob)\n",
    "rf_acc = accuracy_score(y_test, rf_pred)\n",
    "\n",
    "# Step 10: Compare model performance\n",
    "results = pd.DataFrame({\n",
    "    'Model': ['Logistic Regression', 'Random Forest', 'Gradient Boosting'],\n",
    "    'AUC-ROC': [logreg_auc, rf_auc, gb_auc],\n",
    "    'Accuracy': [logreg_acc, rf_acc, gb_acc]\n",
    "})\n",
    "\n",
    "# Highlight best model\n",
    "best_model_name = results.sort_values(by='AUC-ROC', ascending=False).iloc[0]['Model']\n",
    "\n",
    "print(\"\\nüìä Updated Model Performance Comparison:\\n\")\n",
    "print(results.to_string(index=False))\n",
    "print(f\"\\n‚úÖ Best model based on AUC-ROC: {best_model_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Report\n",
    "## ‚úÖ Final Model Selection and Conclusion\n",
    "\n",
    "After evaluating three models on both AUC-ROC and accuracy, the **Gradient Boosting Classifier** was selected as the final model due to its **highest AUC-ROC score of 0.845**, placing it in the **5 SP scoring tier**.\n",
    "\n",
    "### üîç Model Comparison:\n",
    "| Model               | AUC-ROC | Accuracy |\n",
    "|--------------------|---------|----------|\n",
    "| Logistic Regression| 0.830   | 0.792    |\n",
    "| Random Forest      | 0.819   | 0.789    |\n",
    "| **Gradient Boosting** | **0.845** ‚úÖ | 0.752    |\n",
    "\n",
    "### üí° Strategic Insight:\n",
    "- The best model was trained using **upsampled data** to correct for class imbalance.\n",
    "- Churn is highest among customers on **month-to-month contracts** and those **not using add-on services** like TechSupport or OnlineSecurity.\n",
    "- Customers with **fiber optic internet** churn more frequently than DSL users.\n",
    "- A significant portion of users use **non-digital payment methods** (e.g., mailed checks), suggesting a potentially older customer base.\n",
    "\n",
    "### üìà Business Recommendation:\n",
    "Interconnect should focus churn reduction efforts on:\n",
    "- Encouraging longer-term contracts using **No Price Increase Guarantees**\n",
    "- Bundling promotions with security or support services\n",
    "- Simplifying billing and offering education/support for older customers\n",
    "\n",
    "These steps are expected to improve customer retention and reduce churn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìò Project Reflection Report\n",
    "\n",
    "**1. What steps of the plan were performed and what steps were skipped?**\n",
    "- All required steps were completed: data loading, preprocessing, upsampling to fix class imbalance, and training multiple models (logistic regression, random forest, gradient boosting).\n",
    "- No steps were skipped. The only limitation was the model selection scope, as only allowed classifiers (no imblearn or exotic methods) were used due to environment constraints.\n",
    "\n",
    "**2. What difficulties did you encounter and how did you solve them?**\n",
    "- **Class imbalance** initially led to low recall in earlier models. This was resolved using **manual upsampling**.\n",
    "- Reviewer feedback noted that logistic regression alone was insufficient, prompting the use of gradient boosting for improvement.\n",
    "- Some classifiers (e.g., HistGradientBoosting) were unavailable in the environment; fallback was to standard GradientBoostingClassifier.\n",
    "\n",
    "**3. What were some of the key steps to solving the task?**\n",
    "- **Feature encoding and scaling**, along with carefully handling missing values.\n",
    "- **Addressing class imbalance** through upsampling.\n",
    "- Comparing model performance using **AUC-ROC**, the project‚Äôs primary metric.\n",
    "\n",
    "**4. What is your final model and what quality score does it have?**\n",
    "- The final model is **Gradient Boosting Classifier**.\n",
    "- It achieved an **AUC-ROC score of 0.845**, placing it in the **5 SP scoring bracket**."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
